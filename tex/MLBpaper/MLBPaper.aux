\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\newlabel{S:1}{{1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Data}{2}}
\newlabel{S:2}{{2}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Batters with more hits and a higher batting average are inducted}}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Tree-Based Methods for Classification}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Classification Trees}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Decision Tree for Survival of Boat Disaster}}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Aftermath of Boat Disaster}}{5}}
\citation{ISLR}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Ensemble Methods}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Tree Bagging}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Random Forest}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces A Random Forest. The prediction for \textbf  {y} is made by majority vote. \textbf  {get a new figure}}}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Prediction Models}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Classification Tree}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces An unpruned tree}}{8}}
\bibstyle{model1-num-names}
\bibdata{sample.bib}
\bibcite{ISLR}{{1}{2014}{{Hastie}}{{}}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Tree size against misclassifications}}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Random Forest}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusions}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Our pruned tree with 7 terminal nodes}}{11}}
